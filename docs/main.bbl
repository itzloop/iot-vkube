% Generated by ieeetr-fa.bst,  version: 0.6 (2011/07/01), for XePersian Package
% Authors: M.Amintoosi and M.Vahedi
\providecommand{\noopsort}[1]{}
\begin{thebibliography}{10}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{tan-bansal-2019-lxmert}
H.~Tan and M.~Bansal, ``{LXMERT}: Learning cross-modality encoder
  representations from transformers,''  in {\em Proceedings of the 2019
  Conference on Empirical Methods in Natural Language Processing and the 9th
  International Joint Conference on Natural Language Processing
  (EMNLP-IJCNLP)}, (Hong Kong, China),  pp.5100--5111, Association for
  Computational Linguistics, Nov. 2019.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{li-etal-2020-bert-vision}
L.~H. Li, M.~Yatskar, D.~Yin, C.-J. Hsieh, and K.-W. Chang, ``What does {BERT}
  with vision look at?,''  in {\em Proceedings of the 58th Annual Meeting of
  the Association for Computational Linguistics}, (Online),  pp.5265--5275,
  Association for Computational Linguistics, July 2020.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{zhang2019bertscore}
T.~Zhang, V.~Kishore, F.~Wu, K.~Q. Weinberger, and Y.~Artzi, ``Bertscore:
  Evaluating text generation with bert,'' {\em arXiv preprint
  arXiv:1904.09675}, 2019.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{He_2016_CVPR}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,''  in {\em Proceedings of the IEEE Conference on Computer Vision
  and Pattern Recognition (CVPR)}, June 2016.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{Redmon_2016_CVPR}
J.~Redmon, S.~Divvala, R.~Girshick, and A.~Farhadi, ``You only look once:
  Unified, real-time object detection,''  in {\em Proceedings of the IEEE
  Conference on Computer Vision and Pattern Recognition (CVPR)}, June 2016.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{He_2015_ICCV}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Delving deep into rectifiers: Surpassing
  human-level performance on imagenet classification,''  in {\em Proceedings of
  the IEEE International Conference on Computer Vision (ICCV)}, December 2015.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{VQA}
S.~Antol, A.~Agrawal, J.~Lu, M.~Mitchell, D.~Batra, C.~L. Zitnick, and
  D.~Parikh, ``{VQA}: {V}isual {Q}uestion {A}nswering,''  in {\em International
  Conference on Computer Vision (ICCV)}, 2015.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{tensorflow2015-whitepaper}
M.~Abadi, A.~Agarwal, P.~Barham, E.~Brevdo, Z.~Chen, C.~Citro, G.~S. Corrado,
  A.~Davis, J.~Dean, M.~Devin, S.~Ghemawat, I.~Goodfellow, A.~Harp, G.~Irving,
  M.~Isard, Y.~Jia, R.~Jozefowicz, L.~Kaiser, M.~Kudlur, J.~Levenberg,
  D.~Man\'{e}, R.~Monga, S.~Moore, D.~Murray, C.~Olah, M.~Schuster, J.~Shlens,
  B.~Steiner, I.~Sutskever, K.~Talwar, P.~Tucker, V.~Vanhoucke, V.~Vasudevan,
  F.~Vi\'{e}gas, O.~Vinyals, P.~Warden, M.~Wattenberg, M.~Wicke, Y.~Yu, and
  X.~Zheng, ``{TensorFlow}: Large-scale machine learning on heterogeneous
  systems,'' 2015.
\newblock Software available from tensorflow.org.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{NEURIPS2019_9015}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen,
  Z.~Lin, N.~Gimelshein, L.~Antiga, A.~Desmaison, A.~Kopf, E.~Yang, Z.~DeVito,
  M.~Raison, A.~Tejani, S.~Chilamkurthy, B.~Steiner, L.~Fang, J.~Bai, and
  S.~Chintala, ``Pytorch: An imperative style, high-performance deep learning
  library,''  in {\em Advances in Neural Information Processing Systems 32},
  pp.8024--8035, Curran Associates, Inc., 2019.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{sontag1995computational}
E.~D. SoNTAG and H.~Siegelmann, ``On the computational power of neural nets,''
  {\em J. Comp. Syst. Sci},  vol.50,  pp.132--150, 1995.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{DBLP:journals/corr/BahdanauCB14}
D.~Bahdanau, K.~Cho, and Y.~Bengio, ``Neural machine translation by jointly
  learning to align and translate,''  in {\em 3rd International Conference on
  Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015,
  Conference Track Proceedings} (Y.~Bengio and Y.~LeCun,  eds. ), 2015.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{luong-etal-2015-effective}
T.~Luong, H.~Pham, and C.~D. Manning, ``Effective approaches to attention-based
  neural machine translation,''  in {\em Proceedings of the 2015 Conference on
  Empirical Methods in Natural Language Processing}, (Lisbon, Portugal),
  pp.1412--1421, Association for Computational Linguistics, Sept. 2015.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{cheng-etal-2016-long}
J.~Cheng, L.~Dong, and M.~Lapata, ``Long short-term memory-networks for machine
  reading,''  in {\em Proceedings of the 2016 Conference on Empirical Methods
  in Natural Language Processing}, (Austin, Texas),  pp.551--561, Association
  for Computational Linguistics, Nov. 2016.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{NIPS2017_3f5ee243}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez, L.~u.
  Kaiser, and I.~Polosukhin, ``Attention is all you need,''  in {\em Advances
  in Neural Information Processing Systems} (I.~Guyon, U.~V. Luxburg,
  S.~Bengio, H.~Wallach, R.~Fergus, S.~Vishwanathan, and R.~Garnett,  eds. ),
  vol.30, Curran Associates, Inc., 2017.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{fukui-etal-2016-multimodal}
A.~Fukui, D.~H. Park, D.~Yang, A.~Rohrbach, T.~Darrell, and M.~Rohrbach,
  ``Multimodal compact bilinear pooling for visual question answering and
  visual grounding,''  in {\em Proceedings of the 2016 Conference on Empirical
  Methods in Natural Language Processing}, (Austin, Texas),  pp.457--468,
  Association for Computational Linguistics, Nov. 2016.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{kim2016hadamard}
J.-H. Kim, K.-W. On, W.~Lim, J.~Kim, J.-W. Ha, and B.-T. Zhang, ``Hadamard
  product for low-rank bilinear pooling,'' {\em arXiv preprint
  arXiv:1610.04325}, 2016.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{yang2016stacked}
Z.~Yang, X.~He, J.~Gao, L.~Deng, and A.~Smola, ``Stacked attention networks for
  image question answering,''  in {\em Proceedings of the IEEE conference on
  computer vision and pattern recognition},  pp.21--29, 2016.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{NIPS2016_9dcb88e0}
J.~Lu, J.~Yang, D.~Batra, and D.~Parikh, ``Hierarchical question-image
  co-attention for visual question answering,''  in {\em Advances in Neural
  Information Processing Systems} (D.~Lee, M.~Sugiyama, U.~Luxburg, I.~Guyon,
  and R.~Garnett,  eds. ),  vol.29, Curran Associates, Inc., 2016.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{nguyen2018improved}
D.-K. Nguyen and T.~Okatani, ``Improved fusion of visual and language
  representations by dense symmetric co-attention for visual question
  answering,''  in {\em Proceedings of the IEEE conference on computer vision
  and pattern recognition},  pp.6087--6096, 2018.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{teney2017graph}
D.~Teney, L.~Liu, and A.~van Den~Hengel, ``Graph-structured representations for
  visual question answering,''  in {\em Proceedings of the IEEE conference on
  computer vision and pattern recognition},  pp.1--9, 2017.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{gao2015you}
H.~Gao, J.~Mao, J.~Zhou, Z.~Huang, L.~Wang, and W.~Xu, ``Are you talking to a
  machine? dataset and methods for multilingual image question,'' {\em Advances
  in neural information processing systems},  vol.28, 2015.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{wu2016ask}
Q.~Wu, P.~Wang, C.~Shen, A.~Dick, and A.~Van Den~Hengel, ``Ask me anything:
  Free-form visual question answering based on knowledge from external
  sources,''  in {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition},  pp.4622--4630, 2016.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{wang2021simvlm}
Z.~Wang, J.~Yu, A.~W. Yu, Z.~Dai, Y.~Tsvetkov, and Y.~Cao, ``Simvlm: Simple
  visual language model pretraining with weak supervision,'' {\em arXiv
  preprint arXiv:2108.10904}, 2021.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{pmlr-v139-cho21a}
J.~Cho, J.~Lei, H.~Tan, and M.~Bansal, ``Unifying vision-and-language tasks via
  text generation,''  in {\em Proceedings of the 38th International Conference
  on Machine Learning} (M.~Meila and T.~Zhang,  eds. ),  vol.139 of {\em
  Proceedings of Machine Learning Research},  pp.1931--1942, PMLR, 18--24 Jul
  2021.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{zellers2019recognition}
R.~Zellers, Y.~Bisk, A.~Farhadi, and Y.~Choi, ``From recognition to cognition:
  Visual commonsense reasoning,''  in {\em Proceedings of the IEEE/CVF
  conference on computer vision and pattern recognition},  pp.6720--6731, 2019.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{li2018vqa}
Q.~Li, Q.~Tao, S.~Joty, J.~Cai, and J.~Luo, ``Vqa-e: Explaining, elaborating,
  and enhancing your answers for visual questions,''  in {\em Proceedings of
  the European Conference on Computer Vision (ECCV)},  pp.552--567, 2018.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{schwenk2022okvqa}
D.~Schwenk, A.~Khandelwal, C.~Clark, K.~Marino, and R.~Mottaghi, ``A-okvqa: A
  benchmark for visual question answering using world knowledge,''  in {\em
  Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel,
  October 23--27, 2022, Proceedings, Part VIII},  pp.146--162, Springer, 2022.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{anderson2018bottom}
P.~Anderson, X.~He, C.~Buehler, D.~Teney, M.~Johnson, S.~Gould, and L.~Zhang,
  ``Bottom-up and top-down attention for image captioning and visual question
  answering,''  in {\em Proceedings of the IEEE conference on computer vision
  and pattern recognition},  pp.6077--6086, 2018.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{ren2015faster}
S.~Ren, K.~He, R.~Girshick, and J.~Sun, ``Faster r-cnn: Towards real-time
  object detection with region proposal networks,'' {\em Advances in neural
  information processing systems},  vol.28, 2015.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{papineni2002bleu}
K.~Papineni, S.~Roukos, T.~Ward, and W.-J. Zhu, ``Bleu: a method for automatic
  evaluation of machine translation,''  in {\em Proceedings of the 40th annual
  meeting of the Association for Computational Linguistics},  pp.311--318,
  2002.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{lin2004rouge}
C.-Y. Lin, ``Rouge: A package for automatic evaluation of summaries,''  in {\em
  Text summarization branches out},  pp.74--81, 2004.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{banerjee2005meteor}
S.~Banerjee and A.~Lavie, ``Meteor: An automatic metric for mt evaluation with
  improved correlation with human judgments,''  in {\em Proceedings of the acl
  workshop on intrinsic and extrinsic evaluation measures for machine
  translation and/or summarization},  pp.65--72, 2005.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{shin2016color}
A.~Shin, Y.~Ushiku, and T.~Harada, ``The color of the cat is gray: 1 million
  full-sentences visual question answering (fsvqa),'' {\em arXiv preprint
  arXiv:1609.06657}, 2016.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{caesar2018coco}
H.~Caesar, J.~Uijlings, and V.~Ferrari, ``Coco-stuff: Thing and stuff classes
  in context,''  in {\em Proceedings of the IEEE conference on computer vision
  and pattern recognition},  pp.1209--1218, 2018.

\end{LTRbibitems}

\end{thebibliography}
